import pandas as pd
import numpy as np
import sklearn as sk
from sklearn.ensemble import RandomForestClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.model_selection import train_test_split, cross_val_predict
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt
from sklearn.model_selection import GridSearchCV

rf_clf = RandomForestClassifier(n_estimators = 10, max_leaf_nodes = 10, random_state = 1)
knn_clf = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean', metric_params=None, n_jobs=1, n_neighbors=2, p=2, weights='uniform')

classifier = MultiOutputClassifier(knn_clf, n_jobs=-1)
x_train1 = pd.read_csv('resources/MVI_9139_fg2.csv', header=None)
y_train1 = pd.read_csv('resources/MVI_9139_a.csv', header=None)
y_train2 = pd.read_csv('resources/MVI_9129_a.csv', header=None)
x_train2 = pd.read_csv('resources/MVI_9129_fg.csv', header=None)

x_all = x_train1
y_all = y_train1

print(x_all)
y_all = y_all.drop(14, axis=1)


x_train, x_test, y_train, y_test = train_test_split(x_all, y_all, test_size=0.30, random_state = 0)

crossAccuracyList = []
accuracyList = []

# Calculating error for K values between 1 and 40
for j in range(1, 11):
    for i in range(3, 7):
        knn = KNeighborsClassifier(n_neighbors=j)
        knn.fit(x_train, y_train[i])
        asdf = knn.predict(x_train)
        for k in range(0, len(asdf)):
            print(y_train[i])
            print('tzu')
            print(asdf[k])
            if y_train[i][k] == asdf[k]:
                print('top')
        crossAccuracyList.append(accuracy_score(y_train[i], knn.predict(x_train)))
        accuracyList.append(accuracy_score(y_test[i], knn.predict(x_test)))
        print(y_train[i])

figure = plt.figure(figsize=(12, 6))
plt.plot(range(0, 40), accuracyList, color='red', linestyle='dashed', marker='o',
         markerfacecolor='red', markersize=10, label='test_accuracy')
plt.plot(range(0, 40), crossAccuracyList, color='blue', linestyle='dashed', marker='o',
         markerfacecolor='blue', markersize=10, label='train_accuracy')
plt.title('Accuracy as function of k (number of neighbours)')
plt.xlabel('K Value')
plt.ylabel('Accuracy')
plt.grid(True)
plt.show()
print(figure)

grid_params = {
    'n_neighbors': np.arange(1, 30, 1),
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}

gs = GridSearchCV(KNeighborsClassifier(),
                  grid_params,
                  verbose=1,
                  cv=3,
                  n_jobs=-1)
gs_results = gs.fit(x_train, y_train[1])

print('Score:\t{}'.format(gs_results.best_score_))
print('Estimator:\t{}'.format(gs_results.best_estimator_))
print('Params:\t{}'.format(gs_results.best_params_))
'''
classifier.fit(x_train, y_train)

y_rf_pred_train = classifier.predict(x_train)

y_rf_pred_test = classifier.predict(x_test)

target_pred = classifier.predict(x_all)
np.savetxt('teat.csv', target_pred, delimiter=',', fmt='%s')
print(target_pred)
print(classifier.score(x_train, y_train))
print(classifier.score(x_test, y_test))
'''